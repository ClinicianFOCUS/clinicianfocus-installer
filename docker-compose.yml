services:
  FreeScribe-Backend:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                - gpu
    container_name: freescribe-llm-engine
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
      - ${model_path}:/${model}
      - ./gemma-it.jinja:/gemma-it.jinja
    networks:
      - FreeScribe-Backend-Network
    ipc: host
    environment:
      - HF_TOKEN= ${hf_token}
    image: alpindale/aphrodite-openai:latest
    command: --model ${model}
  caddy:
    container_name: freescribe-caddy
    image: caddy:latest
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
    ports:
      - 5551:5551
      - 5541:5541
    networks:
      - FreeScribe-Backend-Network
    depends_on:
      - FreeScribe-Backend
  whisper-server:
    container_name: whisper-server
    build:
      context: ./
      dockerfile: ./whisper-server/Dockerfile
    working_dir: /
    volumes:
      - ./whisper-server/server.py:/server.py
    networks:
      - FreeScribe-Backend-Network
    command: ["python", "server.py", "--port", "2224", "--whispermodel", "tiny"]

networks:
  FreeScribe-Backend-Network:
    driver: bridge
